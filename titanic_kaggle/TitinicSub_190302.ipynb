{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import seaborn as sb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\wonca\\Desktop\\DA_Proj\\TitanicData\\train.csv',header = 'infer',encoding = 'latin1')\n",
    "test = pd.read_csv(r'C:\\Users\\wonca\\Desktop\\DA_Proj\\TitanicData\\test.csv',header = 'infer',encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train,test],ignore_index=True,sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr        783\n",
       "Miss      262\n",
       "Mrs       203\n",
       "Master     61\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "titleReg = re.compile(r',\\s+(\\w+).')\n",
    "for name in df.Name : \n",
    "    title.append(titleReg.search(name).group(1))\n",
    "title = pd.Series(title,name = 'title')\n",
    "title[(title=='Dr') | (title == 'Rev' )| (title == 'Major') | (title == 'Col') | (title == 'Capt') | (title == 'Don') |( title == 'Sir') | (title == 'Jonkheer')] = 'Mr'\n",
    "title[title == 'Mlle'] = 'Miss'\n",
    "title[(title == 'Lady')|(title == 'Mme')|(title == 'Ms')|(title == 'the')|(title=='Dona')] = 'Mrs'\n",
    "title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanAge = df.loc[:,['Age','title']].groupby('title').mean()\n",
    "n = df.shape[0]\n",
    "Age = []\n",
    "for i in range(n):\n",
    "    if np.isnan(df.Age[i]):\n",
    "        if df.title[i] == 'Mr': Age.append(float(meanAge.loc['Mr']))\n",
    "        elif df.title[i] == 'Mrs' : Age.append(float(meanAge.loc['Mrs']))\n",
    "        elif df.title[i] == 'Master' : Age.append(float(meanAge.loc['Master']))\n",
    "        else : Age.append(float(meanAge.loc['Miss']))\n",
    "    else:\n",
    "        Age.append(df.Age[i])\n",
    "df.Age = pd.Series(Age,name='Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[61,'Embarked'] = 'C'\n",
    "df.loc[829,'Embarked'] = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Cabin',inplace=True)\n",
    "df.drop(columns= 'Name',inplace = True)\n",
    "df.drop(columns = 'PassengerId',inplace = True)\n",
    "df['FamSize'] = df['SibSp']+df['Parch']+1\n",
    "df.drop(columns='SibSp',inplace = True)\n",
    "df.drop(columns= 'Parch',inplace = True)\n",
    "df.drop(columns = 'Ticket',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df.shape[0]\n",
    "fam = []\n",
    "for i in range(n):\n",
    "    if df.FamSize[i] == 1:fam.append('single')\n",
    "    elif 1<df.FamSize[i]<5 : fam.append('small')\n",
    "    elif 5<df.FamSize[i]<8 : fam.append('big')\n",
    "    else : fam.append('large')\n",
    "df['Fam'] = pd.Series(fam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age\n",
    "LE = LabelEncoder()\n",
    "df['AgeCut'] = LE.fit_transform(pd.qcut(df.Age,5))\n",
    "ageLi = list(df.loc[:,['Survived','AgeCut']].groupby('AgeCut').mean().sort_values(by = 'Survived',ascending = True).index)\n",
    "ageDic = {ageLi[i]:i for i in range(0,len(ageLi))}\n",
    "df['AgeCut'] = df.AgeCut.apply(lambda x : ageDic[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.qcut(df.Fare,20).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fare\n",
    "LE = LabelEncoder()\n",
    "df['FareCut'] = LE.fit_transform(pd.qcut(df.Fare,20))\n",
    "\n",
    "fl = list(df.loc[:,['FareCut','Survived']].groupby('FareCut').mean().sort_values(by = 'Survived').index)\n",
    "fdic = {fl[i]: i for i in range(0,len(fl))}\n",
    "df['FareCut'] = df.FareCut.apply(lambda x : fdic[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAM 은 더미변수로 치환\n",
    "fd = pd.get_dummies(df.Fam,drop_first= True, prefix= 'Fam')\n",
    "#df = df.join(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex\n",
    "LE = LabelEncoder()\n",
    "df.Sex = LE.fit_transform(df.Sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embarked\n",
    "dic = {'S':0,'Q':1,'C':2}\n",
    "df.Embarked = df.Embarked.apply(lambda x : dic[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titie\n",
    "td = pd.get_dummies(df.title, drop_first= True, prefix= 'title')\n",
    "df= df.join(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFin = df.drop(columns=['title','Fam','Age','Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>FamSize</th>\n",
       "      <th>AgeCut</th>\n",
       "      <th>FareCut</th>\n",
       "      <th>title_Miss</th>\n",
       "      <th>title_Mr</th>\n",
       "      <th>title_Mrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Embarked  Pclass  Sex  Survived  FamSize  AgeCut  FareCut  title_Miss  \\\n",
       "0         0       3    1       0.0        2       3        3           0   \n",
       "1         2       1    0       1.0        2       4       15           0   \n",
       "2         0       3    0       1.0        1       3        4           1   \n",
       "3         0       1    0       1.0        2       4       16           0   \n",
       "4         0       3    1       0.0        1       4        4           0   \n",
       "\n",
       "   title_Mr  title_Mrs  \n",
       "0         1          0  \n",
       "1         0          1  \n",
       "2         0          0  \n",
       "3         0          1  \n",
       "4         1          0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDat = dfFin.loc[:890,:]\n",
    "testDat = dfFin.loc[891:,:].drop(columns = 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = trainDat.drop(columns='Survived')\n",
    "yTrain = trainDat.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pl\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "glm = LogisticRegression()\n",
    "glm.fit(xTrain,yTrain)\n",
    "yPred = glm.predict(testDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPred = pd.Series(yPred,name = 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPred = yPred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.concat([test.PassengerId, yPred], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('sub3.csv',index = False,encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_grid = [0.1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "gamma_grid = [0.0001, 0.0002,0.0005, 0.0006, 0.0007, 0.0008, 0.001,  0.002, 0.005]\n",
    "parameters = {'C': C_grid, 'gamma' : gamma_grid}\n",
    "gridCV = GridSearchCV(SVC(kernel='rbf'), parameters, cv=5);\n",
    "gridCV.fit(xTrain, yTrain)\n",
    "best_C = gridCV.best_params_['C']\n",
    "best_gamma = gridCV.best_params_['gamma']\n",
    "SVM_best = SVC(C=best_C,gamma=best_gamma)\n",
    "SVM_best.fit(xTrain, yTrain);\n",
    "y_pred = SVM_best.predict(testDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPred = yPred.astype(int)\n",
    "sub = pd.concat([test.PassengerId, yPred], axis = 1)\n",
    "sub.to_csv('sub4.csv',index = False,encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## randomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree 하고는 스텝에서 조금 차이가 있음\n",
    "estimator_grid = np.arange(1, 30, 5)\n",
    "depth_grid = np.arange(1, 10, 2)\n",
    "parameters = {'n_estimators': estimator_grid, 'max_depth': depth_grid}\n",
    "gridCV = GridSearchCV(RandomForestClassifier(), param_grid=parameters, cv=10)\n",
    "gridCV.fit(xTrain, yTrain)\n",
    "best_n_estim = gridCV.best_params_['n_estimators']\n",
    "best_depth = gridCV.best_params_['max_depth']\n",
    "RF_best = RandomForestClassifier(max_depth=best_depth,n_estimators=best_n_estim,random_state=3)\n",
    "RF_best.fit(xTrain, yTrain);\n",
    "YpredRF = RF_best.predict(testDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator_grid\n",
    "estimator_grid = np.arange(30, 80, 10)\n",
    "learning_rate_grid = np.array([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])\n",
    "parameters = {'n_estimators': estimator_grid, 'learning_rate': learning_rate_grid}\n",
    "gridCV = GridSearchCV(AdaBoostClassifier(), param_grid=parameters, cv=10)\n",
    "gridCV.fit(xTrain, yTrain)\n",
    "best_n_estim = gridCV.best_params_['n_estimators']\n",
    "best_learn_rate = gridCV.best_params_['learning_rate']\n",
    "AB_best = AdaBoostClassifier(n_estimators=best_n_estim,learning_rate=best_learn_rate,random_state=3)\n",
    "AB_best.fit(xTrain, yTrain);\n",
    "YpredAB = AB_best.predict(testDat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "YpredRF = pd.Series(YpredRF,name = 'Survived')\n",
    "YpredRF = YpredRF.astype(int)\n",
    "sub = pd.concat([test.PassengerId, YpredRF], axis = 1)\n",
    "sub.to_csv('subRF.csv',index = False,encoding='latin1')\n",
    "\n",
    "YpredAB = pd.Series(YpredAB,name = 'Survived')\n",
    "YpredAB = YpredRF.astype(int)\n",
    "sub = pd.concat([test.PassengerId, YpredAB], axis = 1)\n",
    "sub.to_csv('subAB.csv',index = False,encoding='latin1')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YpredRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
